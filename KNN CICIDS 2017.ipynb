{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aa999dc-0a49-4fa8-a543-f23c5a1aa968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import pandas as pd \n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "249e8563-6436-40ff-9c25-9b897c5453ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in ./venv/lib/python3.11/site-packages (from seaborn) (1.26.1)\n",
      "Requirement already satisfied: pandas>=1.2 in ./venv/lib/python3.11/site-packages (from seaborn) (2.1.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in ./venv/lib/python3.11/site-packages (from seaborn) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./venv/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n",
      "Downloading seaborn-0.13.0-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71b0133b-801d-46a9-bd5e-10aa5308cfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.11.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./venv/lib/python3.11/site-packages (from imbalanced-learn) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./venv/lib/python3.11/site-packages (from imbalanced-learn) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in ./venv/lib/python3.11/site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./venv/lib/python3.11/site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.11/site-packages (from imbalanced-learn) (3.2.0)\n",
      "Downloading imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.6/235.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d959934b-73fd-453c-8925-684c1cefc31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pranav/Desktop/ML/Project/archive/MachineLearningCSV/MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv\n",
      "/home/pranav/Desktop/ML/Project/archive/MachineLearningCSV/MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
      "/home/pranav/Desktop/ML/Project/archive/MachineLearningCSV/MachineLearningCVE/Monday-WorkingHours.pcap_ISCX.csv\n",
      "/home/pranav/Desktop/ML/Project/archive/MachineLearningCSV/MachineLearningCVE/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
      "/home/pranav/Desktop/ML/Project/archive/MachineLearningCSV/MachineLearningCVE/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\n",
      "/home/pranav/Desktop/ML/Project/archive/MachineLearningCSV/MachineLearningCVE/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\n",
      "/home/pranav/Desktop/ML/Project/archive/MachineLearningCSV/MachineLearningCVE/Wednesday-workingHours.pcap_ISCX.csv\n",
      "/home/pranav/Desktop/ML/Project/archive/MachineLearningCSV/MachineLearningCVE/Friday-WorkingHours-Morning.pcap_ISCX.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/home/pranav/Desktop/ML/Project/archive/MachineLearningCSV/MachineLearningCVE'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a11f7be-aca7-4d6c-9f26-d646f1c5d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "low_memory=False\n",
    "df1 = pd.read_csv(\"/home/pranav/Desktop/ML/Project/MachineLearningCSV/MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\")\n",
    "df2=pd.read_csv(\"/home/pranav/Desktop/ML/Project/MachineLearningCSV/MachineLearningCVE/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\")\n",
    "df3=pd.read_csv(\"/home/pranav/Desktop/ML/Project/MachineLearningCSV/MachineLearningCVE/Friday-WorkingHours-Morning.pcap_ISCX.csv\")\n",
    "df4=pd.read_csv(\"/home/pranav/Desktop/ML/Project/MachineLearningCSV/MachineLearningCVE/Monday-WorkingHours.pcap_ISCX.csv\")\n",
    "df5=pd.read_csv(\"/home/pranav/Desktop/ML/Project/MachineLearningCSV/MachineLearningCVE/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\")\n",
    "df6=pd.read_csv(\"/home/pranav/Desktop/ML/Project/MachineLearningCSV/MachineLearningCVE/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\")\n",
    "df7=pd.read_csv(\"/home/pranav/Desktop/ML/Project/MachineLearningCSV/MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv\")\n",
    "df8=pd.read_csv(\"/home/pranav/Desktop/ML/Project/MachineLearningCSV/MachineLearningCVE/Wednesday-workingHours.pcap_ISCX.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e103f883-0099-47a1-840f-f9ea97b24231",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df1,df2,df3,df4,df5,df6,df7,df8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8516b4af-6a01-4744-b8a0-67b73e365b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Label\n",
       "BENIGN                        2273097\n",
       "DoS Hulk                       231073\n",
       "PortScan                       158930\n",
       "DDoS                           128027\n",
       "DoS GoldenEye                   10293\n",
       "FTP-Patator                      7938\n",
       "SSH-Patator                      5897\n",
       "DoS slowloris                    5796\n",
       "DoS Slowhttptest                 5499\n",
       "Bot                              1966\n",
       "Web Attack � Brute Force         1507\n",
       "Web Attack � XSS                  652\n",
       "Infiltration                       36\n",
       "Web Attack � Sql Injection         21\n",
       "Heartbleed                         11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[' Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c6b25ff-d48d-43a5-8458-308364c6b98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2830743, 79)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d00e2bb-c9e6-4bec-91d1-0bcb579c6593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates(keep=\"first\")\n",
    "\n",
    "# Remove rows with NaN, positive infinity, or negative infinity\n",
    "df = df[~df.isin([np.nan, np.inf, -np.inf]).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60043641-84e7-4b77-8ee8-476330a9da12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2520798, 79)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bd44f7b-6d06-47ad-9728-f882f85eaf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert int64 into int32 and float64 into float32\n",
    "integer = []\n",
    "f = []\n",
    "for i in df.columns[:-1]:\n",
    "    if df[i].dtype == \"int64\":\n",
    "        integer.append(i)\n",
    "    elif df[i].dtype == \"float64\":\n",
    "        f.append(i)\n",
    "\n",
    "df[integer] = df[integer].astype(\"int32\")\n",
    "df[f] = df[f].astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8d075c0-46ec-4bff-8b8e-2247661556ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude non-numeric columns\n",
    "numeric_df = df.select_dtypes(include=['int32', 'float32'])\n",
    "\n",
    "# Calculate the correlation matrix for numeric columns\n",
    "corr_matrix = numeric_df.corr()\n",
    "\n",
    "# Define the correlation threshold\n",
    "threshold = 0.85\n",
    "\n",
    "# Find highly correlated features\n",
    "corr_features = set()\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "            colname = corr_matrix.columns[i]\n",
    "            corr_features.add(colname)\n",
    "\n",
    "# Drop highly correlated features from the original DataFrame\n",
    "df.drop(corr_features, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d05bd24-6c4d-4807-a513-d918d3212257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2520798, 44)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "988ca9c7-4c00-42a8-bc3e-23fb9081f02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Label\n",
       "BENIGN                        2095057\n",
       "DoS Hulk                       172846\n",
       "DDoS                           128014\n",
       "PortScan                        90694\n",
       "DoS GoldenEye                   10286\n",
       "FTP-Patator                      5931\n",
       "DoS slowloris                    5385\n",
       "DoS Slowhttptest                 5228\n",
       "SSH-Patator                      3219\n",
       "Bot                              1948\n",
       "Web Attack � Brute Force         1470\n",
       "Web Attack � XSS                  652\n",
       "Infiltration                       36\n",
       "Web Attack � Sql Injection         21\n",
       "Heartbleed                         11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[' Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30b52d63-335b-41ea-b8a1-0cf34bcf3c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Label\n",
       "BENIGN           2095057\n",
       "DoS Hulk          172846\n",
       "DDoS              128014\n",
       "PortScan           90694\n",
       "DoS GoldenEye      10286\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new dataframe with the attacks that have more than 10000 instances in the original dataframe\n",
    "df1=df.groupby(' Label').filter(lambda x:len(x)>10000)\n",
    "df1[' Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff6c769d-f725-4f01-8301-8d8408a30867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Label\n",
       "FTP-Patator                   5931\n",
       "DoS slowloris                 5385\n",
       "DoS Slowhttptest              5228\n",
       "SSH-Patator                   3219\n",
       "Bot                           1948\n",
       "Web Attack � Brute Force      1470\n",
       "Web Attack � XSS               652\n",
       "Infiltration                    36\n",
       "Web Attack � Sql Injection      21\n",
       "Heartbleed                      11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new dataframe with the attacks that have less than 10000 instances in the original dataframe\n",
    "df2=df.groupby(' Label').filter(lambda x:len(x)<10000)\n",
    "df2[' Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9a4af03-3d5b-41c2-a9fb-2d23596d6a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df1.drop([' Label'],axis=1)\n",
    "y = df1[' Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8378d006-5301-4e72-9b93-b1a247b9557e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('BENIGN', 2095057), ('DDoS', 128014), ('DoS GoldenEye', 10286), ('DoS Hulk', 172846), ('PortScan', 90694)]\n"
     ]
    }
   ],
   "source": [
    "unique, countsa = np.unique(y, return_counts=True)\n",
    "print(list(zip(unique,countsa)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ce0bd6e-a646-456c-90e8-2ff21eb78357",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Down sample the first dataframe (attacks with more than 10000) so that each calss has around 10000 instances. A random undersampling is oerformed for the purpose.\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "rus.fit(x, y)\n",
    "Xn, yn = rus.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "158c1969-e8fc-4327-8e70-41fb589b6163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('BENIGN', 10286), ('DDoS', 10286), ('DoS GoldenEye', 10286), ('DoS Hulk', 10286), ('PortScan', 10286)]\n"
     ]
    }
   ],
   "source": [
    "unique, countsb = np.unique(yn, return_counts=True)\n",
    "print(list(zip(unique,countsb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c8076c2-672a-4427-a50b-fb1be13716a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Label\n",
       "BENIGN           10286\n",
       "DDoS             10286\n",
       "DoS GoldenEye    10286\n",
       "DoS Hulk         10286\n",
       "PortScan         10286\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.concat([Xn,yn],axis=1)\n",
    "df1[' Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f95e4528-95b7-42d4-97e1-04b7739eaf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Label\n",
       "BENIGN                        10286\n",
       "DDoS                          10286\n",
       "DoS GoldenEye                 10286\n",
       "DoS Hulk                      10286\n",
       "PortScan                      10286\n",
       "FTP-Patator                    5931\n",
       "DoS slowloris                  5385\n",
       "DoS Slowhttptest               5228\n",
       "SSH-Patator                    3219\n",
       "Bot                            1948\n",
       "Web Attack � Brute Force       1470\n",
       "Web Attack � XSS                652\n",
       "Infiltration                     36\n",
       "Web Attack � Sql Injection       21\n",
       "Heartbleed                       11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.concat([df1,df2])\n",
    "df[' Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec114c3e-06cd-4157-a828-adb3ecd338e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop([' Label'],axis=1)\n",
    "y = df[' Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62a5132b-d98f-45f7-95d3-a203262f3ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the categorical labels into numerical\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y=le.fit_transform(df[' Label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3cff071e-df3f-4f5f-9a0c-9fa550024cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 10286), (1, 1948), (2, 10286), (3, 10286), (4, 10286), (5, 5228), (6, 5385), (7, 5931), (8, 11), (9, 36), (10, 10286), (11, 3219), (12, 1470), (13, 21), (14, 652)]\n"
     ]
    }
   ],
   "source": [
    "unique, counts1 = np.unique(y, return_counts=True)\n",
    "print(list(zip(unique,counts1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7dbc41e-dcdf-4f56-bdec-5e4ff1a1e3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling with SMOTE to balance the dataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "#strategy ={0:16805,1:16805,2:16805,3:16805,4:16805,5:16805,6:16805,7:16805,8:16805,9:16805,10:16805,11:16805,12:16805,13:16805,14:16805}\n",
    "oversample = SMOTE(random_state=42)\n",
    "Xn,Yn = oversample.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17ecbd84-8420-43ee-9047-d95549809c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 10286), (1, 10286), (2, 10286), (3, 10286), (4, 10286), (5, 10286), (6, 10286), (7, 10286), (8, 10286), (9, 10286), (10, 10286), (11, 10286), (12, 10286), (13, 10286), (14, 10286)]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(Yn, return_counts=True)\n",
    "print(list(zip(unique,counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cccb6042-a226-412e-a4b9-af47d093b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(Xn,Yn,test_size=0.30,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e7942bf-f211-4a8e-9fe9-a057d636a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create an instance of SimpleImputer with 'mean' strategy to replace NaN values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Fit the imputer to X_train and transform X_train and X_test with it\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Apply StandardScaler to X_train and X_test\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "97972c82-b7be-414d-acc2-c52f037bf3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train model:  0.01997661590576172  seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "KNN.fit(X_train, Y_train) \n",
    "print(\"Time taken to train model: \", time.time()-start,\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2234e068-42da-4955-ba2f-1f71048637bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "Predict_X =  KNN.predict(X_train)\n",
    "scores = cross_val_score(KNN, X_train, Y_train, cv=7)\n",
    "accuracy = metrics.accuracy_score(Y_train,Predict_X)\n",
    "confusion_matrix = metrics.confusion_matrix(Y_train, Predict_X)\n",
    "classification = metrics.classification_report(Y_train, Predict_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0f33731-7cc9-4ffd-8f30-d8eeeed8b31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "Predict_X =  KNN.predict(X_train)\n",
    "scores = cross_val_score(KNN, X_train, Y_train, cv=7)\n",
    "accuracy = metrics.accuracy_score(Y_train,Predict_X)\n",
    "confusion_matrix = metrics.confusion_matrix(Y_train, Predict_X)\n",
    "classification = metrics.classification_report(Y_train, Predict_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18423632-d7ac-4951-8083-2263c68407d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Results OF TEST--------------------------------\n",
      "Cross Validation Accuracy Score: 96.43%\n",
      "Accuracy Score: 96.47%\n",
      "F1 Score: 96.45%\n",
      "Recall Score: 96.47%\n",
      "Precision Score: 96.44%\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      3075\n",
      "           1       0.98      1.00      0.99      3114\n",
      "           2       1.00      1.00      1.00      3044\n",
      "           3       0.99      1.00      1.00      3025\n",
      "           4       0.99      1.00      0.99      3111\n",
      "           5       0.99      0.99      0.99      3076\n",
      "           6       0.99      0.99      0.99      3080\n",
      "           7       1.00      1.00      1.00      3043\n",
      "           8       1.00      1.00      1.00      3092\n",
      "           9       0.99      1.00      1.00      3135\n",
      "          10       0.99      1.00      0.99      3081\n",
      "          11       0.99      0.99      0.99      3151\n",
      "          12       0.79      0.77      0.78      3110\n",
      "          13       0.97      0.99      0.98      3056\n",
      "          14       0.79      0.79      0.79      3094\n",
      "\n",
      "    accuracy                           0.96     46287\n",
      "   macro avg       0.96      0.96      0.96     46287\n",
      "weighted avg       0.96      0.96      0.96     46287\n",
      "\n",
      "F1 Macro Score: 96.46%\n",
      "F1 Micro Score: 96.47%\n"
     ]
    }
   ],
   "source": [
    "#Performance \n",
    "print('--------------------------- Results OF TEST--------------------------------')\n",
    "Predict_X = KNN.predict(X_test)\n",
    "#scores = cross_val_score(KNN, X_test, Y_test, cv=7)\n",
    "print(f\"Cross Validation Accuracy Score: {scores.mean() * 100:.2f}%\")\n",
    "print(f\"Accuracy Score: {metrics.accuracy_score(Y_test,Predict_X) * 100:.2f}%\")\n",
    "print(f\"F1 Score: {metrics.f1_score(Y_test,Predict_X, average='weighted') * 100:.2f}%\")\n",
    "print(f\"Recall Score: {metrics.recall_score(Y_test,Predict_X, average='weighted') * 100:.2f}%\")\n",
    "print(f\"Precision Score: {metrics.precision_score(Y_test,Predict_X, average='weighted') * 100:.2f}%\")\n",
    "classification = metrics.classification_report(Y_test, Predict_X)\n",
    "print(\"Classification report:\" \"\\n\", classification) \n",
    "print(f\"F1 Macro Score: {metrics.f1_score(Y_test,Predict_X, average='macro') * 100:.2f}%\")\n",
    "print(f\"F1 Micro Score: {metrics.f1_score(Y_test,Predict_X, average='micro') * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52700711-f761-437f-903a-e7a2d4f2f9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
